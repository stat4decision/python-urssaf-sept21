{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc81140",
   "metadata": {},
   "source": [
    "# Les équivalences SAS / Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ff441",
   "metadata": {},
   "source": [
    "Python n'est pas un logiciel de traitement de données, il faut donc utiliser des packages pour travailler sur des données en python.\n",
    "\n",
    "Dans notre cas, nous allons nous concentrer sur 3 packages :\n",
    "\n",
    "- Pandas pour la manipulation de données\n",
    "- Scikit-learn pour les modèles de machine learning\n",
    "- Statsmodels pour les modèles statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention cette cellule doit être lancée au début de chaque session\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de35e0",
   "metadata": {},
   "source": [
    "## L'équivalent d'une table <--> le DataFrame de pandas\n",
    "\n",
    "En python, vos tables vont être stockées dans des DataFrame\n",
    "\n",
    "Avant d'importer des données, il faut apprendre ce qu'est un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b0083",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les Series de Pandas\n",
    "\n",
    "- Les Series sont indexées, c'est leur avantage sur les arrays de NumPy\n",
    "- On peut utiliser les fonctions `.values` et `.index` pour voir les différentes parties de chaque Series\n",
    "- On définit une Series par `pd.Series([,], index=['','',])`\n",
    "- On peut appeler un élément avec `ma_serie['France']`\n",
    "- On peut aussi faire des conditions :\n",
    "```python\n",
    "ma_serie[ma_serie>5000000]\n",
    "```\n",
    "```\n",
    "'France' in ma_serie\n",
    "```\n",
    "- Les objets Series peuvent être transformés en dictionnaires en utilisant :\n",
    "`.to_dict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([3,5,7,3,2],index=[\"lundi\",\"mardi\", \"mercredi\", \"jeudi\", \"vendredi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30152832",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Définir un objet Series comprenant le nombre d'habitant par région de 5 régions puis afficher les régions avec plus de 5'000'000 d'habitants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_pop = pd.Series(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(ser_pop) == pd.Series\n",
    "print(\"Bien créée !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_pop_5M = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert ser_pop_5M.min() >= 100000\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4545db91",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# D'autres opérations sur les objets series\n",
    "\n",
    "- Pour définir le nom de la Series, on utilise `.name`\n",
    "- Pour définir le titre de la colonne des observations, on utilise `.index.name`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a908f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Définir les noms de l’objet et de la colonne des pays pour la Series précédente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5186e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_pop.name = \"populations\"\n",
    "ser_pop.index.name = \"région\"\n",
    "ser_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee595a34",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les données manquantes\n",
    "\n",
    "Dans pandas, les données manquantes sont identifiés avec les fonctions de Numpy (`np.nan`). On a d'autres fonctions telles que :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d645caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_manquant = pd.Series([2,np.nan,4],index=['a','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee389c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_manquant.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d9e74",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.isna(pd.Series([2,np.nan,4],index=['a','b','c']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f7c26",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.notna(pd.Series([2,np.nan,4],index=['a','b','c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c7f9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les dates avec pandas\n",
    "\n",
    "- Python possède un module datetime qui permet de gérer facilement des dates\n",
    "- Pandas permet d'appliquer les opérations sur les dates aux Series et aux DataFrame\n",
    "- Le format es dates Python est `YYYY-MM-DD HH:MM:SS`\n",
    "\n",
    "- On peut générer des dates avec la fonction `pd.date_range()` avec différente fréquences `freq=`\n",
    "- On peut utiliser ces dates comme index dans un DataFrame ou dans un objet Series\n",
    "- On peut changer la fréquence en utilisant `.asfreq()`\n",
    "- Pour transformer une chaine de caractère en date, on utilise `pd.to_datetime()` avec l’option `dayfirst=True` si on est dans le cas français\n",
    "-On pourra aussi spécifier un format pour accélérer le processus `%Y%m%d`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0249db",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "\n",
    "Créez un objet Series et ajoutez des dates partant du 3 octobre 2017 par jour jusqu’à aujourd’hui. Afficher le résultat dans un graphique (on utilisera la méthode `.plot()`\n",
    "\n",
    "*Indice :* Utilisez les informations ci-dessus\n",
    "\n",
    "On utilisera :\n",
    "```\n",
    "pd.date_range(___)\n",
    "np.random.randn(___)\n",
    "pd.Series(___)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dates = ___\n",
    "valeurs = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_temp = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d04a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert len(serie_temp) == len(dates)\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87329a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Le DataFrame \n",
    "\n",
    "- Les DataFrame sont des objets très souples pouvant être construits de différentes façon\n",
    "- On peut les construire en récupérant des données copier / coller, où directement sur Internet, ou en entrant les valeurs manuellement\n",
    "\n",
    "\n",
    "- Les DataFrame se rapprochent des dictionnaires et on peut construire ces objets en utilisant `DataFrame(dico)`\n",
    "- De nombreux détails sur la création des DataFrame se trouve sur ce site :\n",
    "\n",
    "<http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af72bb8d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Construction de DataFrame\n",
    "\n",
    "On peut simplement construire un DataFrame avec le classe pd.DataFrame() à partir de différentes structures :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751570c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "frame1=pd.DataFrame(np.random.randn(10).reshape(5,2),\n",
    "             index=[\"obs_\"+ str(i) for i in range(5)],\n",
    "             columns=[\"col_\"+ str(i) for i in range(2)])\n",
    "frame1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd100eef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Opérations sur les DataFrame\n",
    "\n",
    "On peut afficher le nom des colonnes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409e748",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(frame1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025247c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut accéder à une colonne avec :\n",
    "- `frame1.col_0` : attention au cas de nom de colonnes avec des espaces...\n",
    "- `frame1['col_0']`\n",
    "\n",
    "On peut accéder à une cellule avec :\n",
    "- `frame1.loc['obs1','col_0']` : on utilise les index et le nom des colonnes\n",
    "- `frame1.iloc[1,0]` : on utilise les positions dans le DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986042b",
   "metadata": {},
   "source": [
    "# De SAS à python, l'importation des données\n",
    "\n",
    "Quel que soit le type de données, il y a une fonctin en python pour charger les données dans un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2682fa",
   "metadata": {},
   "source": [
    "## Le chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b399a",
   "metadata": {},
   "source": [
    "Quel que soit le type de fichier, on utilise pandas.\n",
    "\n",
    "Pandas permet de charger de nombreux fichiers avec :\n",
    "    `pd.read_...()` en remplaçant les ... par le type de fichier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e1b977",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importation de données avec Pandas\n",
    "\n",
    "Quel que soit le type de fichier, Pandas possède une fonction :\n",
    "```python\n",
    "frame=pd.read_...('chemin_du_fichier/nom_du_fichier',...)\n",
    "```\n",
    "Pour écrire un DataFrame dans un fichier, on utilise :\n",
    "```python\n",
    "frame.to_...('chemin_du_fichier/nom_du_fichier',...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c931b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Importer un fichier `.csv` avec `pd.read_csv()`. On utilisera le fichier \"./data/airbnb.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ddaec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc3d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert airbnb[\"price\"].dtype == object\n",
    "print(\"Bien importé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ecd67d",
   "metadata": {},
   "source": [
    "Importer un fichier `.csv` qui a comme séparateur `;`, le nom du fichier est `base-dpt.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1723f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c009e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(base_dpt) == pd.DataFrame\n",
    "print(\"Bien importé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cd9146",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## HTML\n",
    "On utilise `pd.read_html(url)`. Cet fonction est basée sur les packages `beautifulsoup` et `html5lib`\n",
    "\n",
    "Cette fonction renvoie une liste de DataFrame qui représentent tous les DataFrame de la page. On ira ensuite chercher l'élément qui nous intéresse avec `frame_list[0]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef29c64",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Importez un tableau en html depuis la page <https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdae01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318dfca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_bank = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e964b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(frame_bank) == pd.DataFrame\n",
    "print(\"Bien importé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66927979",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Importer depuis Excel\n",
    "\n",
    "On a deux approches pour Excel :\n",
    "- On peut utiliser `pd.read_excel()`\n",
    "- On peut utiliser la classe `pd.ExcelFile()`\n",
    "\n",
    "Dans ce cas, on utilise :\n",
    "```python\n",
    "xlsfile=pd.ExcelFile('fichier.xlsx')\n",
    "xlsfile.parse('Sheet1')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e69e855",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :** \n",
    "    \n",
    "Importez un fichier Excel avec les deux approches, on utilisera : `credit2.xlsx` et `ville.xls`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35f449",
   "metadata": {},
   "source": [
    "1- avec `pd.read_excel()` pour le fichier `credit2.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit2 = pd.read_excel(\"./data/credit2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b752dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert credit2[\"Age\"].max() == 83\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96a825",
   "metadata": {},
   "source": [
    "2- avec `pd.ExcelFile()` pour le fichier `ville.xls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b432aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_ville = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(frame_ville) == pd.DataFrame\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0bf339",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Importer des données SQL\n",
    "\n",
    "Pandas possède une fonction `read_sql()` qui permet d’importer directement des bases de données ou des queries dans des DataFrame\n",
    "\n",
    "Il faut tout de même un connecteur pour accéder aux bases de données\n",
    "\n",
    "Pour mettre en place ce connecteur, on utlise le package SQLAlchemy.\n",
    "\n",
    "Suivant le type de base de données, on utilisera différents codes mais la structure du code est toujours la même"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827676e8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# on importe l'outil de connexion\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5133b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On crée une connexion\n",
    "```python\n",
    "connexion=create_engine(\"sqlite:///(...).sqlite\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07e7b0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On utlise une des fonctions de Pandas pour charger les données\n",
    "```python\n",
    "requete=\"\"\"select ... from ...\"\"\"\n",
    "frame_sql=pd.read_sql_query(requete,connexion)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c086ea52",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercices :**\n",
    "    \n",
    "Importez la base de données SQLite salaries et récupérez la table Salaries dans un DataFrame \n",
    "\n",
    "*Indice :* On commence par créer la connexion et ensuite on fait la requête `select * from salaries`, la connexion se fait en utilisant l'adresse : \"sqlite:///./data/salaries.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1ef9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354338c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(salaries) == pd.DataFrame\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad765a",
   "metadata": {},
   "source": [
    "## Importer des données SAS\n",
    "\n",
    "Les données SAS ont un format propriétaire qui est bien souvent difficile à gérer dans d'autres outils.\n",
    "\n",
    "Pandas peut gérer des fichiers SAS en utilisant la fonction `pd.read_sas(___)` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61c996f",
   "metadata": {},
   "source": [
    "**Exercice :**\n",
    "Importez le fichier `bce_uai.sas7bdat` en utilisant pandas\n",
    "\n",
    "*Indice :* L'encodage des chaînes de caractères est spécifique en SAS, on utilisera l'option `encoding='latin-1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d799cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(bce_uai) == pd.DataFrame\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142a246",
   "metadata": {},
   "source": [
    "### Utilisation de pyreadstat\n",
    "\n",
    "Pour aller plus loin, on peut utiliser le package `pyreadstat`. Il permet de récupérer les metadata de votre fichier SAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514454c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ace0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on charge directement deux objets, un DataFrame et un fichier de format\n",
    "df_person, format_df_person = pyreadstat.read_sas7bdat(\"./data/person.sas7bdat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d523f",
   "metadata": {},
   "source": [
    "Si on veut changer les labels des colonnes, on peut utiliser :\n",
    "    \n",
    "`df.rename(columns=format_df.column_names_to_labels)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff084e4",
   "metadata": {},
   "source": [
    "**Exercice :** Récupérer le fichier person.sas7bdat et changer les noms des colonnes en noms longs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c89dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person2 = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcab2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  df_person.columns[0] == 'Line number of person'\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d754ee0",
   "metadata": {},
   "source": [
    "# La proc Contents\n",
    "\n",
    "```\n",
    "PROC CONTENTS \n",
    "      DATA=data_frame \n",
    "     SHORT ;\n",
    "RUN ;\n",
    "```\n",
    "\n",
    "```{python}\n",
    "data_frame.columns\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e60296",
   "metadata": {},
   "source": [
    "**Exercice :** Affichez les colonnes de votre DataFrame bce_uai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a53100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f78a9499",
   "metadata": {},
   "source": [
    "```\n",
    "PROC CONTENTS \n",
    "      DATA=data_frame ;\n",
    "RUN ;\n",
    "```\n",
    "\n",
    "```{python}\n",
    "data_frame.info(verbose = 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f7bf7",
   "metadata": {},
   "source": [
    "**Exercice :** Affichez les détails du DataFrame bce_uai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850ce79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3efd076",
   "metadata": {},
   "source": [
    "## Associer un nom long à une colonne Pandas\n",
    "\n",
    "Python ne possède pas nativement de proc format pour associer des labels longs aux labels courts pour les affichages. Le plus simple est de construire un dictionnaire :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c8967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'classes_ages':[1,2,3,4,5,6,7,5,6]})\n",
    "d = {1:'0-23',2:'24-27',3:'48-59',4:'60-71',5:'72-79',6:'80-87',7:'88-99'}\n",
    "\n",
    "df.replace({\"classes_ages\": d})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a01462",
   "metadata": {},
   "source": [
    "Le type categorical permet de conserver directement cette information :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a4a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'age_group':[1,2,3,4,5,6,7]}, \n",
    "                  dtype=\"category\")\n",
    "\n",
    "# Rename categories\n",
    "df.age_group = df.age_group.cat.rename_categories(d)\n",
    "\n",
    "df.age_group.cat.codes\n",
    "df.age_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7724610",
   "metadata": {},
   "source": [
    "# La proc print\n",
    "\n",
    "Il s'agit juste de la fonction `print()` de python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf8e5e",
   "metadata": {},
   "source": [
    "Pour afficher un DataFrame avec des conditions, on utilise :\n",
    "    \n",
    "`df[df[\"a\"]>10]`\n",
    "\n",
    "Pour afficher uniquement certaines colonnes :\n",
    "\n",
    "`df[[\"a\",\"b\"]]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552bb33",
   "metadata": {},
   "source": [
    "**Exercice :** Utilisez les manipulations de DataFrame pour afficher les colonnes \"price\" et \"zipcode\" avec uniquement les \"zipcode\" égaux à 75015.\n",
    "Stockez le résultats dans l'objet new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d5fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe08a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  new_df.shape[0] == 2892\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383e53c",
   "metadata": {},
   "source": [
    "# Les étapes DATA\n",
    "\n",
    "Ajouter une variable en pandas est simple :\n",
    "    \n",
    "`df[\"new_a\"] = df[\"a\"] * 2`\n",
    "\n",
    "Avec une condition :\n",
    "    \n",
    "`df.loc[df[\"a\"]>0, \"new_a\"] = 10`\n",
    "\n",
    "ou \n",
    "\n",
    "`df[\"b\"] = np.where(df[\"a\"]<0, 1,0)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534ea60a",
   "metadata": {},
   "source": [
    "**Exercice :** Construire une nouvelle colonne à partir de la colonne \"zipcode\" avec des 1 pour chaque valeur égales à 75015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb[\"is_75015\"] = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bafb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  airbnb[\"is_75015\"].max() == 1\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329ae87",
   "metadata": {},
   "source": [
    "Modifier ce qui est dans une colonne est simple en pandas, si on utilise un type spécial, on utilisera :\n",
    "    \n",
    "- pour une donnée textuelle :\n",
    "    `df[\"col_test\"].str.___`, ___ peut être remplacé par n'importe quelle méthode liée aux chaînes de caractères\n",
    "\n",
    "- pour une donnée de date :\n",
    "    `df[\"col_test\"].dt.___`, ___ peut être remplacé par n'importe quelle méthode liée aux objets datetime de python\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7ca18",
   "metadata": {},
   "source": [
    "**Exercice :** Extraire deux colonnes avec le jour et le mois à partir de la colonne DATE_OUVERTURE du data frame bce_uai en utlisant `.dt.day` et `.dt.month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_uai[\"jour_ouverture\"] = ___\n",
    "bce_uai[\"mois_ouverture\"] = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  bce_uai[\"jour_ouverture\"].min() == 1\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e79861",
   "metadata": {},
   "source": [
    "**Exercice avancé :**\n",
    "    Utilisez des transformations pour rendre la colonne price de airbnb numérique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ccd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on utilisera pd.to_numeric()\n",
    "\n",
    "airbnb[\"price_num\"] = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f79f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  airbnb[\"price_num\"].dtype == np.number\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9ab9bb",
   "metadata": {},
   "source": [
    "## Les concaténations avec python \n",
    "\n",
    "On utlise la fonction `pd.concat()`, cette fonction gèrera le cas des données manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7417e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les jointures avec Pandas\n",
    "\n",
    "On veut joindre des jeux de données en utilisant des clés (variables communes)\n",
    "\n",
    "- `pd.merge()` permet de joindre deux DataFrame, on utilise comme options `on='key'`\n",
    "\n",
    "- On peut utiliser comme option `how=`, on peut avoir :\n",
    "    - `left` dans ce cas, on garde le jeu de données à gauche et pour les données de droite des valeurs manquantes sont ajoutées.\n",
    "    - `outer`, on garde toutes les valeurs des deux jeux de données\n",
    "    - ...\n",
    "\n",
    "- On peut avoir plusieurs clés et faire une jointure sur les deux clés `on=['key1','key2']`\n",
    "\n",
    "Pour plus de détails : <http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.merge.html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c1139",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Joindre deux dataframes (credit1 et credit2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d576e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "credit_merged = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6588838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  credit1.shape[0] == credit_merged.shape[0]\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea33c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discrétisation\n",
    "\n",
    "Pour discrétiser, on utilise la fonction `pd.cut()`, on va définir une liste de points pour discrétiser et on entre cette liste comme second paramètre de la fonction.\n",
    "\n",
    "Une fois discrétisé, on peut afficher les modalités obtenues en utilisant `.categories`\n",
    "\n",
    "On peut aussi compter les occurrence en utilisant `pd.value_counts()`\n",
    "\n",
    "Il est aussi possible d’entrer le nombre de segments comme second paramètre\n",
    "\n",
    "On utilisera aussi `qcut()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f8d5f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Créez une variable dans le dataframe AirBnB pour obtenir des niveaux de prix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5a1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd50cd3b",
   "metadata": {},
   "source": [
    "# La proc Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ff3b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les tris avec Pandas \n",
    "\n",
    "Pour effectuer des tris, on utilise :\n",
    "- `.sort_index()` pour le tri des index\n",
    "- `.sort_values()` pour le tri des données\n",
    "- `.rank()` affiche le rang des observations\n",
    "\n",
    "Il peut y avoir plusieurs tris dans la même opération. Dans ce cas, on utilise des listes de colonnes :\n",
    "```python\n",
    "frame.sort_values([\"col_1\",\"col_2\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93948e0",
   "metadata": {},
   "source": [
    "En SAS, on aura :\n",
    "    \n",
    "```\n",
    "PROC SORT\n",
    "      DATA=df_in\n",
    "       OUT=df_out ;\n",
    "  BY var ;\n",
    "RUN ;\n",
    "```\n",
    "\n",
    "En python, cela donnera :\n",
    "```\n",
    "df_out = df_in.sort_values(\"var\")\n",
    "```\n",
    "\n",
    "### Pour aller plus loin\n",
    "```\n",
    "PROC SORT\n",
    "      DATA=df_in\n",
    "       OUT=df_out ;\n",
    "  BY var1\n",
    "     DESCENDING var2 ;\n",
    "RUN ;\n",
    "```\n",
    "\n",
    "En python cela donne :\n",
    "```\n",
    "df_out = df_in*.sort_values([\"var1\", \"var2\"], ascending = [True, False])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f62715",
   "metadata": {},
   "source": [
    "**Exercice :** \n",
    "Trier les logements airbnb par prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c37ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584eb744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  airbnb.price_num.max() = airbnb.price_num.loc[-1]\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea4a01a",
   "metadata": {},
   "source": [
    "**Exercice :** Trier les salaires en utilisant JobTitle et TotalPay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618dff03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb07ba8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gestion des doublons\n",
    "\n",
    "- On utilise `.duplicated()` ou `.drop_duplicates()` dans le cas où on désire effacer les lignes se répétant\n",
    "\n",
    "\n",
    "- On peut se concentrer sur une seule variables en entrant directement le nom de la variable. Dans ce cas, c’est la première apparition qui compte. Si on veut prendre la dernière apparition, on utilise l’option `keep=\"last\"`. On pourra avoir :\n",
    "```python\n",
    "frame1.drop_duplicates([\"col_0\",\"col_1\"],keep=\"last\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab08c99",
   "metadata": {},
   "source": [
    "# La proc Means\n",
    "\n",
    "La proc means est une procédure centrale de SAS pour décrire une variable. Python utilise différentes fonctions pour remplacer la proc means.\n",
    "\n",
    "Pour décrire une variable ou toutes les variables, on utilise la méthode `.describe()`.\n",
    "\n",
    "Si on veut combiner des statistiques on utilisera `.agg()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d55f6",
   "metadata": {},
   "source": [
    "Si on veut étudier les modalités d'une variable qualitative, on utilise : `.value_counts()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04910e81",
   "metadata": {},
   "source": [
    "```\n",
    "PROC MEANS \n",
    "      DATA=df\n",
    "      MEAN ;\n",
    "  VAR var1 ;\n",
    "RUN ;\n",
    "```\n",
    "équivalent python :\n",
    "```\n",
    "df[\"var1\"].mean()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbafbc7",
   "metadata": {},
   "source": [
    "Si on veut aller plus loin, et traduire :\n",
    "```\n",
    "PROC MEANS \n",
    "  DATA=df ;\n",
    "  VAR var1 ;\n",
    "  CLASS var2 ;\n",
    "RUN ;\n",
    "```\n",
    "On utilisera alors un nouvel outil, l'outil `groupby()`\n",
    "```\n",
    "df.groupby(\"var2\")[\"var1].mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc7b2eb",
   "metadata": {},
   "source": [
    "**Excercice :** Extraire les statistiques descriptives pour la colonne TotalPay du dataframe Salaries.\n",
    "Par ailleurs, obtenir les salaires moyens par JobTitle. Stockez ces résultats dans un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828e62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87309fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaires_moy_job = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41896471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  salaires_moy_job[\"TotalPay\"].max() < salaries[\"TotalPay\"].max()\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31198161",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L'utilisation de GroupBy sur des DataFrame\n",
    "\n",
    "- `.groupby` permet de rassembler des observations en fonction d’une variable dite de groupe\n",
    "\n",
    "\n",
    "- Par exemple, `frame.groupby('X').mean()` donnera les moyennes par groupes de `X`\n",
    "\n",
    "\n",
    "- On peut aussi utiliser `.size()` pour connaître la taille des groupes et utiliser d’autres fonctions (`.sum()`)\n",
    "\n",
    "\n",
    "- On peut effectuer de nombreuses opérations de traitement avec le groupby\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc71e84",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "- Données sur les salaires\n",
    "\n",
    "\n",
    "- On utilise le `groupby()` pour rassembler les types d’emploi\n",
    "\n",
    "\n",
    "- Et on calcule des statistiques pour chaque type\n",
    "\n",
    "\n",
    "On peut utiliser la méthode `.agg()` avec par exemple `'mean'` comme paramètre\n",
    "\n",
    "On utilise aussi fréquemment la méthode `.apply()` combinée à une fonction lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081e07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc47baf0",
   "metadata": {},
   "source": [
    "# La proc FREQ\n",
    "\n",
    "La procédure Freq calcule des comptages et des croisements de variables. Pandas a pour cela deux méthodes :\n",
    "- `.value_counts()`\n",
    "- `pd.crosstab()`\n",
    "\n",
    "Par exemple : \n",
    "```\n",
    "PROC FREQ\n",
    "      DATA=df ;\n",
    "  TABLE var1 ;\n",
    "RUN ;\n",
    "```\n",
    "est équivalent à :\n",
    "```\n",
    "df[\"var1\"].value_counts(normalize=True) * 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172053f",
   "metadata": {},
   "source": [
    "La proc Freq permet aussi de générer des tableaux croisés. Ainsi, on aura :\n",
    "```\n",
    "PROC FREQ\n",
    "      DATA=a ;\n",
    "  TABLE b*c ;\n",
    "RUN ;\n",
    "```\n",
    "L'équivalent python sera donc :\n",
    "```\n",
    "pd.crosstab(index = df[\"var1\"], columns = df[\"var2\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bfe4c",
   "metadata": {},
   "source": [
    "**Exercice :** Obtenez les distributions des fréquences par SECTEUR_CONTRAT et triez les par ordre alphanumérique. Stockez le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c70603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "secteur_distrib = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  secteur_distrib.max() == 56786\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b5891",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Afficher un tableau Pivot pour les données AirBnB. On croise `cancellation_policy` et `room_type` et on compte les occurences et stockez le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7053f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_airbnb = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  cross_airbnb.iloc[0,0] == 16789\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e68e2d",
   "metadata": {},
   "source": [
    "# Proc SQL\n",
    "\n",
    "Bien souvent en SAS, vous utlisez la proc SQL. Pandas est proche du langage SQL avec notamment les groupby. Pour s'en rapprocher encore, on peut utiliser `.query()`\n",
    "\n",
    "```\n",
    "PROC SQL ;\n",
    "  SELECT var1, var2\n",
    "  FROM df\n",
    "  WHERE var1>0 ;\n",
    "QUIT ;\n",
    "```\n",
    "On a beaucoup de fonctions pour y arriver :\n",
    "```\n",
    "df[[\"var1\",\"var2\"]][df[\"var1\"]>0]\n",
    "\n",
    "df[[\"var1\",\"var2\"]].query(\"var1>0\")\n",
    "```\n",
    "\n",
    "Aller plus loin :\n",
    "```\n",
    "PROC SQL ;\n",
    "  SELECT SUM(var1)\n",
    "          AS sum_var1\n",
    "  FROM df\n",
    "  GROUP BY var2 ;\n",
    "QUIT ;\n",
    "```\n",
    "Avec python cela revient à :\n",
    "```\n",
    "df.groupby(\"var2\")[\"var1\"].sum().reset_index(name ='sum_var1')\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448b82a1",
   "metadata": {},
   "source": [
    "**Exercice :** Essayez de coder l'équivalent de :\n",
    "```\n",
    "SELECT count(distinct NATURE_UAI) \n",
    "FROM bce_uai\n",
    "WHERE ETAT_ETABLISSEMENT = '1'\n",
    "GROUP BY SECTEUR_PUBLIC_PRIVE\n",
    "```\n",
    "Stockez le résultat dans un objet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44279201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_u_unique = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  bce_u_unique.iloc[0] == 21\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a6f29",
   "metadata": {},
   "source": [
    "# Proc export\n",
    "\n",
    "La proc export est en pandas une méthode qui s'écrit `.to_...`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49719977",
   "metadata": {},
   "source": [
    "**Exercice :** Exportez un dataframe au format Excel en utilisant `.to_excel()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac980f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42a63061",
   "metadata": {},
   "source": [
    "# Macros-programmes et fonctions et classes python\n",
    "\n",
    "Nous avons vu les fonctions lors de la pemère partie de la formation. Une fonction est un macro-programme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77527a9",
   "metadata": {},
   "source": [
    "Dans une fonction, on pourra utiliser directement le code d'exploration avec peu de changements.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe0115",
   "metadata": {},
   "source": [
    "**Exercice :**\n",
    "Construire une fonction capable de charger des données, de les transformer et de sauvegarder le résultat dans un fichier\n",
    "\n",
    "*Quelques indications*\n",
    "\n",
    "On utilisera python et pandas, on complètera la fonction ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7696ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def transfo(file_name, \n",
    "            folder_name,\n",
    "            output_file_name,\n",
    "            output_folder_name,\n",
    "            sep_csv = \",\"\n",
    "           ):\n",
    "    \"\"\"\n",
    "    This function should load a file (csv), clean it and export it to Excel\n",
    "    Here are the steps:\n",
    "     - Remove missing values \n",
    "     - Transform dates to Python date format\n",
    "     - Drop duplicated rows\n",
    "    This function should return 0 if all OK / 1 if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # on commence par importer la donnée en vérifiant qu'elle se trouve dans le répertoire voulu\n",
    "        # pd.read_csv()\n",
    "        \n",
    "\n",
    "        # on applique les transformations en utlisant les outils de pandas\n",
    "        # on supprime les données manquantes\n",
    "        # .dropna()\n",
    "        \n",
    "        \n",
    "        # on essaye de transformer les colonnes de date en format date python\n",
    "        # pd.to_datetime()\n",
    "        # si le terme \"date\" est compris dans le nom de la colonne\n",
    "        \n",
    "        \n",
    "        # on supprime les doublons\n",
    "        # .drop_duplicates()\n",
    "        \n",
    "        \n",
    "        # on exporte les données en vérifiant l'existence du répertoire\n",
    "        # .to_excel()\n",
    "        \n",
    "        return 0\n",
    "    except FileNotFoundError:\n",
    "        print(\"Attention problème de répertoire introuvable\")\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test du fonctionnement\n",
    "assert transfo(folder_name=\"./data/\", \n",
    "               file_name=\"base-dpt.csv\", \n",
    "               output_folder_name=\"./data/\", \n",
    "               output_file_name=\"base-dpt.xlsx\", \n",
    "               sep_csv = \";\") == 0\n",
    "data_temp = pd.read_excel(\"./data/base-dpt.xlsx\")\n",
    "assert data_temp.isna().sum().all() == 0\n",
    "print('Bravo!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7021175",
   "metadata": {},
   "source": [
    "Vous avez créé une fonction équivalente à un macro-programme !\n",
    "\n",
    "On va continuer avec les graphiques en python !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
